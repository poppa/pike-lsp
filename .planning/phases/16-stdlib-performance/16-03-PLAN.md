---
phase: 16-stdlib-performance
plan: 03
type: execute
wave: 3
depends_on: [16-01, 16-02]
files_modified:
  - packages/pike-lsp-server/benchmarks/runner.ts
  - packages/pike-lsp-server/src/tests/stdlib-hover-tests.ts
autonomous: false
user_setup: []

must_haves:
  truths:
    - "First hover on stdlib type responds in under 500ms"
    - "Benchmarks measure stdlib introspection latency"
    - "E2E tests verify hover works for common stdlib modules"
  artifacts:
    - path: "packages/pike-lsp-server/benchmarks/runner.ts"
      provides: "Stdlib performance benchmark suite"
      contains: "Stdlib Performance"
    - path: "packages/pike-lsp-server/src/tests/stdlib-hover-tests.ts"
      provides: "E2E hover tests for stdlib modules"
      exports: ["describe"]
  key_links:
    - from: "benchmark suite"
      to: "PikeBridge.resolveStdlib"
      via: "bridge.resolveStdlib() calls"
      pattern: "resolveStdlib\\("
    - from: "hover tests"
      to: "LSP server hover handler"
      via: "integration test flow"
      pattern: "hover\\(|resolveStdlib\\("
---

<objective>
Add benchmarks and E2E tests to verify stdlib introspection performance (<500ms) and functionality.

Purpose: Validate the stdlib performance fixes with measurable benchmarks and end-to-end tests. Ensure first hover responds in under 500ms and common modules (Stdio, String, Array, Mapping) work correctly.

Output: Benchmark suite showing stdlib introspection latency, and E2E tests verifying hover works.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/16-stdlib-performance/16-RESEARCH.md
@.planning/phases/16-stdlib-performance/16-01-SUMMARY.md
@.planning/phases/16-stdlib-performance/16-02-SUMMARY.md
@.planning/ROADMAP.md
@.planning/STATE.md

@packages/pike-lsp-server/benchmarks/runner.ts
@packages/pike-lsp-server/src/tests/stdlib-tests.ts
@packages/pike-lsp-server/src/tests/performance-tests.ts
</context>

<tasks>

<task type="auto">
  <name>Add stdlib performance benchmarks</name>
  <files>packages/pike-lsp-server/benchmarks/runner.ts</files>
  <action>
    Add a new benchmark group "Stdlib Performance (Warm)" after the "Cross-File Cache Verification" group (around line 212).

    The group should benchmark:
    1. Cold resolve: `resolveStdlib('Stdio')` first call
    2. Warm resolve: `resolveStdlib('Stdio')` cached call
    3. Common modules: resolveStdlib for String, Array, Mapping
    4. Nested module: resolveStdlib for Stdio.File

    Example structure:
    ```typescript
    group('Stdlib Performance (Warm)', async () => {
        // Warm up
        await bridge.resolveStdlib('Stdio');

        bench('resolveStdlib("Stdio") - warm', async () => {
            return await bridge.resolveStdlib('Stdio');
        });

        bench('resolveStdlib("String")', async () => {
            return await bridge.resolveStdlib('String');
        });

        bench('resolveStdlib("Array")', async () => {
            return await bridge.resolveStdlib('Array');
        });

        bench('resolveStdlib("Stdio.File")', async () => {
            return await bridge.resolveStdlib('Stdio.File');
        });
    });
    ```

    Add output reporting similar to the cache stats section that shows average latency.
  </action>
  <verify>grep -n "Stdlib Performance" packages/pike-lsp-server/benchmarks/runner.ts</verify>
  <done>Benchmark group added with 4+ stdlib introspection benches</done>
</task>

<task type="auto">
  <name>Create stdlib hover E2E tests</name>
  <files>packages/pike-lsp-server/src/tests/stdlib-hover-tests.ts</files>
  <action>
    Create a new test file `stdlib-hover-tests.ts` that verifies hover works for stdlib modules.

    Use node:test format (see performance-tests.ts for pattern).

    Test cases:
    1. "should return symbols for Stdio module" - resolveStdlib('Stdio') returns found=true with symbols array
    2. "should return symbols for String module" - resolveStdlib('String') returns found=true with symbols array
    3. "should return symbols for Array module" - resolveStdlib('Array') returns found=true with symbols array
    4. "should return symbols for Mapping module" - resolveStdlib('Mapping') returns found=true with symbols array
    5. "should respond in under 500ms for first stdlib hover" - measure duration, assert < 500ms
    6. "should include common stdlib functions" - verify Stdio has write, read_file, etc.

    Structure:
    ```typescript
    import { describe, it, before, after } from 'node:test';
    import * as assert from 'node:assert/strict';
    import { PikeBridge } from '@pike-lsp/pike-bridge';

    describe('Stdlib Hover Tests', () => {
        let bridge: PikeBridge;

        before(async () => {
            bridge = new PikeBridge();
            await bridge.start();
            bridge.on('stderr', () => {});
        });

        after(async () => {
            await bridge.stop();
        });

        // tests...
    });
    ```

    Run with: `node --test dist/tests/stdlib-hover-tests.js`
  </action>
  <verify>test -f packages/pike-lsp-server/src/tests/stdlib-hover-tests.ts</verify>
  <done>Test file created with 6+ test cases covering common stdlib modules</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Stdlib performance benchmarks and E2E hover tests</what-built>
  <how-to-verify>
    1. Run benchmarks:
                   ```bash
                   cd packages/pike-lsp-server && pnpm benchmark
                   ```

                   Verify "Stdlib Performance" group appears and shows results.

    2. Check all benches report latency (should be < 500ms for warm calls).

    3. Run E2E tests:
                   ```bash
                   cd packages/pike-lsp-server && node --test dist/tests/stdlib-hover-tests.js
                   ```

                   Verify all 6 tests pass.

    4. Manual hover test:
                   ```bash
                   cd packages/vscode-pike
                   # Open a Pike file with: Stdio.File f;
                   # Hover over "Stdio" or "File"
                   # Should see hover info with symbols
                   ```

    Expected results:
    - Benchmarks show stdlib introspection < 500ms (warm)
    - E2E tests all pass
    - Manual hover shows documentation
  </how-to-verify>
  <resume-signal>Type "approved" if benchmarks < 500ms and tests pass, or describe issues</resume-signal>
</task>

</tasks>

<verification>
After checkpoint approval:
- [ ] Benchmarks run successfully showing "Stdlib Performance" group
- [ ] Warm introspection < 500ms for all tested modules
- [ ] E2E tests pass (6/6)
- [ ] Manual hover works in VSCode for stdlib types
</verification>

<success_criteria>
1. Benchmark suite measures stdlib introspection latency
2. All common modules (Stdio, String, Array, Mapping) respond in < 500ms
3. E2E tests verify hover returns symbols for stdlib types
4. STDLIB-03 satisfied: First hover responds in under 500ms
</success_criteria>

<output>
After completion, create `.planning/phases/16-stdlib-performance/16-03-SUMMARY.md`
</output>
